# Product Roadmap

## MVP Phase: Core Foundation

### Application Foundation

1. [x] Next.js Application Foundation & Routing Setup — Set up Next.js 16 App Router with directory structure, TypeScript configuration, base layout with navigation, route groups for authenticated vs public pages, Tailwind CSS with shadcn/ui theme, environment variables, and configuration management to provide the application shell for all features. `S`

2. [x] Monorepo & Prisma Infrastructure Setup — Set up monorepo structure with pnpm workspaces, create packages/database with Prisma schema and client, configure packages/ui for shared components, establish cross-package dependencies, set up Prisma Client exports and singleton pattern, configure migration scripts to work from root and package level, and prepare development tooling. `S`

2b. [x] Package-Based Architecture Migration — Extract existing app logic into reusable packages: migrate UI components and utilities to @compilothq/ui, move database connection and helpers to @compilothq/database, extract validation schemas to @compilothq/validation, update all imports in web app to use packages, configure hot-reloading across packages, and validate development workflow works end-to-end. `M`

**Milestone 1: Foundation Ready** ✓ Development environment established

### Foundation Reference Data & Core Models

3. [x] Foundation Reference Models & Seed Data — Implement core reference data models (Country, DataNature, ProcessingAct, TransferMechanism, RecipientCategories) in Prisma schema, create migrations, test in development environment, and implement comprehensive seed data covering 250+ countries with GDPR classifications, 28 data nature types, 17 processing operations, and 13 recipient categories to provide the foundation for automatic compliance validation and classification throughout the platform. `M`

4. [x] Organization & User Models with Multi-Tenancy — Implement Organization model with settings and metadata, implement User model with UserPersona enum (DPO, PRIVACY_OFFICER, BUSINESS_OWNER, IT_ADMIN, SECURITY_TEAM, LEGAL_TEAM), establish organizationId foreign keys with cascading deletes, add compound indexes for multi-tenant queries, and create migrations testing that all queries properly isolate by organization to establish secure multi-tenancy foundation. `S`

5. [x] Authentication Foundation with NextAuth.js v5 — Set up NextAuth.js with email magic links and Google OAuth, configure Prisma adapter for User and session management, implement organization context in session, create login/signup UI components with organization creation flow, set up protected route middleware injecting user and organizationId into requests, implement complete invitation system with team management UI, and test session management to secure all application features. `M`

6. [x] tRPC API Layer with Auth Context — Set up tRPC v11 server with Next.js App Router integration, create authenticated context injecting user and organizationId from session, implement base router structure organized by domain (processing activities, assessments, vendors), create Zod validation schemas for Organization and User entities, implement authorization middleware ensuring all queries filter by organizationId, set up tRPC client with TanStack Query, and implement error handling to enable type-safe, authorized API communication. `M`

7. [ ] Base UI Component Library Setup — Install and configure shadcn/ui components (Button, Input, Select, Dialog, Sheet, Table, Form) in the packages/ui, set up Radix UI primitives, create reusable form components with React Hook Form and Zod validation, build base layout components (Header with organization switcher, Sidebar with navigation, PageContainer), implement loading states with Suspense boundaries, create error boundaries for graceful failures, and set up toast notification system to provide UI building blocks for all features. `S`

**Milestone 2: Auth & API Foundation** ✓ Secure multi-tenant infrastructure ready

### Core Privacy Entities

8. [x] Processing Activity Model — Implement DataProcessingActivity model with organizationId for multi-tenancy, workflow status tracking (DRAFT, UNDER_REVIEW, APPROVED, ACTIVE, SUSPENDED, ARCHIVED), risk level assessment, DPIA requirement flags (requiresDPIA, dpiaStatus), review date tracking, business owner and processing owner fields, retention period tracking, and metadata JSON field; add compound indexes for dashboard queries (organizationId + status + requiresDPIA, organizationId + nextReviewDate, riskLevel + dpiaStatus); create migrations and test multi-tenant isolation to enable core processing activity management. `S`

9. [ ] Data Subject Category Model — Implement DataSubject model with name, description, category classification, vulnerability flags (isVulnerable) for children/elderly/patients, example descriptions, and audit timestamps; create migrations and test to enable data subject tracking and automatic DPIA requirement detection for vulnerable groups. `S`

10. [ ] Personal Data Category Model — Implement DataCategory model with name, description, sensitivity levels (PUBLIC, INTERNAL, CONFIDENTIAL, RESTRICTED, NORMAL), special category flags (isSpecialCategory) for Article 9 data, example data fields array, references to DataNature for automatic GDPR classification, and audit timestamps; add indexes on sensitivity and isSpecialCategory; create migrations and test to enable automatic special category data detection and legal basis validation. `S`

11. [ ] Purpose & Legal Basis Models — Implement Purpose model with name, description, category classification, internal/external flags, and audit timestamps for documenting processing objectives; implement LegalBasis model with name, description, regulatory framework (GDPR, LGPD, etc.), article references, consent requirement flags, and audit timestamps supporting all six GDPR legal bases; create migrations and test to enable legal compliance validation and purpose limitation tracking. `S`

12. [ ] Recipient Model with Hierarchy — Implement Recipient model with name, RecipientType enum (INTERNAL_DEPARTMENT, PROCESSOR, SUB_PROCESSOR, INDEPENDENT_CONTROLLER, JOINT_CONTROLLER, PUBLIC_AUTHORITY, THIRD_PARTY), description, optional vendorId reference for processor recipients, self-referential parentRecipientId for sub-processor chains, and audit timestamps; add indexes on type and parentRecipientId; create migrations and test hierarchical queries to enable recipient tracking with sub-processor visibility. `S`

**Milestone 3: Core Entity Models** ✓ Primary compliance entities defined

### Entity Relationships (Junction Tables)

13. [ ] Processing Activity Junction Tables — Implement junction tables linking DataProcessingActivity to Purpose (DataProcessingActivityPurpose), DataSubject (DataProcessingActivityDataSubject), DataCategory (DataProcessingActivityDataCategory), and Recipient (DataProcessingActivityRecipient) with proper foreign key constraints, unique constraints preventing duplicates, and bidirectional indexes; create migrations and test queries to enable many-to-many relationships and granular compliance tracking. `S`

14. [ ] Digital Asset Model — Implement DigitalAsset model with organizationId, name, AssetType enum (DATABASE, APPLICATION, API, FILE_STORAGE, CRM, CLOUD_SERVICE, etc.), description, hosting location, technical and business owner fields, containsPII flag, dataCategories string array, integrationStatus enum (CONNECTED, PENDING, FAILED, NOT_INTEGRATED, MANUAL_ONLY), lastScannedAt timestamp, discoveredVia field for future automation hooks, and metadata JSON; add indexes on organizationId + containsPII; create migrations and test to track systems processing personal data and prepare for future automated discovery. `M`

15. [ ] Asset & Transfer Foundation — Implement many-to-many relationship between DataProcessingActivity and DigitalAsset; implement DataTransfer model with discriminated source/destination pattern (sourceType enum, sourceActivityId/sourceAssetId nullable FKs, destinationType enum, destinationRecipientId/destinationVendorId nullable FKs), geography tracking (sourceCountry, destinationCountry), transfer mechanism reference, risk level, review dates, and TransferStatus enum; implement DataTransferCategory junction table for many-to-many with DataCategory; add comprehensive indexes for geographic and risk queries; create migrations and test to enable cross-border transfer tracking and automatic safeguard requirement detection. `M`

16. [ ] Component Change Tracking System — Implement ComponentChangeLog model with componentType string ("Vendor", "Purpose", "DataCategory"), componentId, changedAt timestamp, changedBy userId, changeType enum (CREATED, UPDATED, DELETED, RESTORED), fieldChanged string (nullable for creation), oldValue JSON, newValue JSON, and changeReason text; implement change detection middleware intercepting all component updates (Vendor, Purpose, DataCategory, LegalBasis, Recipient, DataSubject) capturing before/after state; add batch change detection for bulk operations; build AffectedDocument linking tracking which GeneratedDocuments reference changed components enabling impact analysis ("3 DPIAs reference this vendor, regenerate?"); create indexes on (componentType, componentId, changedAt) and (changedAt) for timeline queries; implement automatic change log creation in tRPC mutations using middleware pattern; test change detection with concurrent updates to prevent race conditions; provide audit timeline visualization to enable complete component history without full versioning overhead. `M`

**Milestone 4: Entity Relationships Complete** ✓ All core entities connected

### Assessment Architecture Foundation

17. [ ] Questionnaire Foundation Models — Implement Questionnaire model with organizationId, name, description, QuestionnaireType enum (DATA_PROCESSING_ACTIVITY, DPIA, VENDOR_ASSESSMENT, etc.), targetEntity string, version tracking, QuestionnaireStatus enum (DRAFT, PUBLISHED, ARCHIVED), publishedAt timestamp, allowPartialSave flag, estimatedMinutes, and audit timestamps; create migrations and test to enable questionnaire template management with versioning. `S`

18. [ ] Questionnaire Version Management — Add parentQuestionnaireId self-reference for version lineage, isCurrentPublished flag for active version designation, publishedAt/archivedAt timestamps for lifecycle tracking, version increment logic preventing gaps, and questionnaireSnapshot JSON preservation of full structure at publication; implement version query helpers (getCurrentPublished, getVersionHistory, getSpecificVersion) with indexes on (organizationId, isCurrentPublished) and parentQuestionnaireId; create migrations testing version chain integrity to enable questionnaire evolution while preserving assessment stability. `S`

19. [ ] Question Model with Conditional Logic — Implement Question model with questionnaireId reference, text, helpText, placeholder, QuestionType enum (DATA_BINDING, CONDITIONAL, CONTEXT_ONLY, RISK_ASSESSMENT, EVIDENCE_REQUEST), AnswerType enum (SHORT_TEXT, LONG_TEXT, SINGLE_SELECT, MULTI_SELECT, YES_NO, DATE, NUMBER, FILE_UPLOAD), isRequired flag, order for sequencing, section grouping, componentMapping JSON for linking answers to entities, isStoredData flag distinguishing persisted vs contextual questions, conditionalLogic JSON with show/hide rules, maxNestingDepth integer (enforced at 3-4 levels to prevent unmaintainable complexity), riskWeight for auto-scoring, options array for select questions, and audit timestamps; add indexes on questionnaireId and order; create migrations and test to enable sophisticated questionnaire logic while preventing complexity anti-patterns. `M`

20. [ ] Base Assessment Model with Snapshot Architecture — Implement Assessment model as workflow container with organizationId, questionnaireId reference, questionnaireVersion INT denormalized for filtering, **questionnaireSnapshot JSON capturing complete question structure at assessment creation** (questions array with id, text, type, options, conditionalLogic, componentMapping), AssessmentType enum, assignedToUserId, dueDate, AssessmentStatus enum, progress percentage, completion timestamps, currentReviewerId,ApprovalStatus, calculatedRiskScore, riskLevel, **snapshotCreatedAt timestamp**, metadata JSON, and audit timestamps; add compound indexes for dashboard queries (organizationId + status + dueDate, assignedToUserId + status, organizationId + assessmentType + status); **implement snapshot creation service capturing questionnaire state atomically at assessment start**; create migrations and test snapshot integrity to enable workflow management with guaranteed question stability. `M`

21. [ ] Discriminated Assessment Pattern — Implement type-specific assessment models: ProcessingActivityAssessment with non-nullable dataProcessingActivityId and one-to-one Assessment relation, VendorAssessment with non-nullable vendorId and one-to-one Assessment relation, and AssetAssessment with non-nullable digitalAssetId and one-to-one Assessment relation; add unique constraints on assessmentId for each, add indexes on entity foreign keys; create migrations and test referential integrity to fix polymorphism issues and enable proper entity-assessment relationships with database-enforced integrity. `M`

22. [ ] Assessment Response with Mapping Integrity — Implement AssessmentResponse model with assessmentId, questionId references, respondentId reference, response JSON for storing raw answers, responseText for display, confidence score for ML-assisted mapping, isValid flag, validationErrors array, and audit timestamps; add unique constraint on (assessmentId, questionId) to prevent duplicate responses; implement separate mapping junction tables (ResponsePurposeMapping, ResponseLegalBasisMapping, ResponseDataCategoryMapping) with responseId and component foreign keys to maintain referential integrity when components are deleted; create migrations and test cascading behavior to enable structured response storage with proper data integrity. `M`

23. [ ] Assessment Workflow State Machine — Implement AssessmentWorkflow model with assessmentId (unique), currentStage enum (DRAFT, SUBMITTED, PRIVACY_REVIEW, IT_REVIEW, LEGAL_REVIEW, DPO_REVIEW, EXECUTIVE_APPROVAL, APPROVED, REJECTED, REVISION_REQUESTED), and audit timestamps; implement WorkflowTransition model tracking fromStage, toStage, WorkflowAction enum (SUBMIT, APPROVE, REJECT, REQUEST_REVISION, ESCALATE, CANCEL, REOPEN), performedBy user reference, performedAt timestamp, comment, and metadata JSON; add indexes on workflowId and performedAt; create migrations and test state transition validation to enable structured workflow tracking with complete audit trail and transition validation. `M`

**Milestone 5: Assessment Architecture Complete**✓ Type-safe questionnaire and workflow foundation ready

### Questionnaire Engine Implementation

24. [ ] Question Rendering Components — Build React components for all AnswerType variants: ShortTextQuestion with Input, LongTextQuestion with Textarea, SingleSelectQuestion with Select/Radio, MultiSelectQuestion with Checkbox groups, YesNoQuestion with Toggle/Radio, DateQuestion with DatePicker, NumberQuestion with numeric Input, FileUploadQuestion with drag-and-drop, implement validation per question type using Zod schemas from question.validation JSON, build QuestionRenderer component routing to appropriate subcomponent based on AnswerType, integrate React Hook Form for state management, and handle disabled/readonly states to enable rich questionnaire UIs. `M`

25. [ ] Conditional Logic Engine — Implement ConditionalLogicEvaluator service parsing conditionalLogic JSON from questions, evaluating show/hide rules based on current form state, supporting operators (equals, contains, greaterThan, in, etc.) for rule matching, handling dependency chains where question B depends on A which depends on C, enforcing maxNestingDepth limit rejecting question configurations exceeding 3-4 levels with clear error messages, implementing useConditionalVisibility React hook providing visible question IDs based on current answers, and build ConditionDebugger dev tool visualizing dependency graph to prevent unmaintainable complexity anti-pattern while enabling sophisticated questionnaire flows. `M`

26. [ ] Response Storage & Validation Service — Implement saveAssessmentResponse tRPC mutation with optimistic updates for responsive UX, validation service checking answer matches expected AnswerType, required field enforcement, conditional validation (validate only if question is visible), componentMapping execution translating answers to entity references, and batch save endpoint for autosave; build response retrieval service with getAssessmentResponses query, implement response diffing for change detection, and create validation error aggregation showing all errors per section; integrate with React Hook Form providing seamless save/load to enable reliable response persistence with immediate validation feedback. `S`

27. [ ] Progress Tracking & Section Navigation — Implement progress calculation service counting completed required questions vs total required per section, calculating overall percentage with weighted sections if configured, updating Assessment.progress on each save, and providing progress breakdown per section; build SectionNavigator component displaying sections with completion indicators (checkmark, partial, empty), progress bars per section, validation error counts per section, and jump-to-section navigation; implement NavigationGuard warning users about unsaved changes and unanswered required questions; integrate with browser back/forward handling section state to enable clear progress visibility and smooth navigation experience. `S`

28. [ ] Questionnaire Version Migration UI — Implement migration strategy enum (NO_MIGRATION, ALLOW_UPGRADE, FORCE_UPGRADE_DRAFT) on Questionnaire model; build UpgradeAvailableBanner component showing in-progress assessment users when newer version exists with comparison summary ("v2 adds 5 questions about AI processing"), answer preservation logic mapping v1 responses to v2 questions where IDs match, upgrade confirmation dialog with preview of new questions and preserved answers; implement gracePeriodDays countdown showing "v1 available until [date]"; create admin PublishNewVersion workflow prompting for migration strategy with impact analysis ("5 in-progress assessments will see upgrade option"), and notification service alerting affected users; build version comparison view showing side-by-side question diff (added/removed/modified); add user preference to decline upgrade with userDeclinedUpgrade flag; test migration logic with complex conditional question chains ensuring logic integrity after upgrade to enable controlled questionnaire evolution with user choice and answer preservation. `M`

**Milestone 6: Questionnaire Engine Complete** ✓ Full questionnaire capabilities with conditional logic

### Processing Activity Discovery Workflow

29. [ ] Discovery Questionnaire Template — Create processing activity intake questionnaire template with 15-20 questions covering project basics (name, description, business owner), data subject identification with multi-select and volume estimation, personal data category selection with automatic special category warnings when Article 9 data selected, purpose documentation with predefined common purposes, legal basis preliminary selection with consent/legitimate interest guidance, external system identification with processor suggestions, automated decision detection with profiling risk flags, and retention period estimation with justification prompts; configure auto-risk detection rules flagging large-scale processing (>10k data subjects), special category data, automated decisions, vulnerable subjects, and international transfers; publish template with version 1.0 to enable business stakeholder self-service. `M`

30. [ ] Response-to-Component Mapping Service — Implement QuestionnaireResponseMapper service extracting structured data from AssessmentResponse records, mapping responses to entity creation/selection based on componentMapping configurations, creating draft DataProcessingActivity with status=DRAFT, populating Activity-Purpose, Activity-DataSubject, Activity-DataCategory, and Activity-Recipient junction tables from multi-select question responses, auto-setting requiresDPIA flag based on screening responses (special categories + large scale = DPIA required), setting riskLevel based on calculated risk score from question riskWeights, assigning created activity to Privacy Officer role for review, and creating ProcessingActivityAssessment linking Assessment to created Activity; implement transaction handling ensuring atomic creation (all entities or none), detailed logging for debugging mapping issues, and validation preventing incomplete activity creation; build admin UI for testing mapping rules to enable automatic activity creation from questionnaire responses with proper data integrity. `L`

31. [ ] Activity Review UI — Build ActivityReviewPage displaying side-by-side layout with left panel showing original questionnaire responses grouped by section with question text and user answers, and right panel showing generated ProcessingActivity component card with all populated fields, linked Purposes displayed as badges with remove capability, linked DataSubjects with category and volume, linked DataCategories with special category highlighting, linked Recipients with type badges, calculated risk level with visual indicator, DPIA requirement flag with justification, and audit trail showing creation source; implement inline editing for all activity fields using same form components as direct creation, real-time validation highlighting missing required fields or compliance issues, approval workflow actions (Approve → status=ACTIVE, Request Changes → status=UNDER_REVISION with comment to submitter, Reject → archive with reason), and diff view highlighting changes made during review; integrate with notification system sending emails to submitter on status changes to enable privacy officer review and approval of business stakeholder submissions. `M`

32. [ ] Activity Approval Workflow — Implement workflow state transitions from DRAFT → UNDER_REVIEW → APPROVED → ACTIVE, role-based permissions (only DPO/PRIVACY_OFFICER can approve, submitter can view status), bulk approval capability for multiple similar activities, rejection with required comment explaining reasons, revision request triggering notifications and allowing submitter to edit and resubmit, and activity locking preventing edits while under review; build WorkflowHistory component displaying all transitions with user, timestamp, action, and comments; create dashboard widgets showing pending approvals count for DPOs and submission status for business users to enable structured approval process with accountability and audit trail. `S`

**Milestone 7: Discovery Workflow Complete** ✓ Business users can create activities via questionnaires

### DPIA Foundation

33.[ ] DPIA Specialized Assessment Model — Implement DPIAAssessment model with assessmentId (unique one-to-one with Assessment), optional dataProcessingActivityId linking to assessed activity, screening flags (involvesSystematicMonitoring, involvesLargeScaleProcessing, involvesAutomatedDecisions, involvesSpecialCategories, involvesVulnerableSubjects, etc.) with Boolean values, screeningScore calculated from flag weights, dpiaRequired determination flag, structured DPIA content fields (processingDescription, necessityJustification, proportionalityJustification, dataFlowDiagram URL, mitigationMeasures, residualRiskLevel, residualRiskAcceptable flag), consultation tracking (dataSubjectsConsulted, dpoConsulted, requiresSAConsultation flags with related text fields), approval tracking (conductedBy, reviewedByDPO, approvedBy, completedDate, nextReviewDate), status enum (NOT_STARTED, IN_PROGRESS, COMPLETED, etc.), version tracking, and audit timestamps; implement DPIARisk model with dpiaAssessmentId reference, RiskCategory enum (UNLAWFUL_PROCESSING, DATA_BREACH_CONFIDENTIALITY, DISCRIMINATION, etc.), riskDescription, likelihood/impact enums, inherentRisk calculation, affectedGroups array, mitigationMeasures text, residual likelihood/impact after mitigation, residualRisk calculation, and RiskStatus enum; add comprehensive indexes for querying by status and risk level; create migrations and test to enable structured DPIA assessments with risk management. `M`

34. [ ] DPIA Screening Questionnaire — Create DPIA screening questionnaire template with 10 screening questions mapping to involvesSystematicMonitoring through involvesPreventsRightsExercise flags, each question weighted for automatic scoring (special categories = 3 points, large scale = 2 points, automated decisions = 3 points, vulnerable subjects = 3 points, etc.), total score threshold (≥7 points = DPIA required), decision logic displayed to user explaining why DPIA is/isn't required with specific regulatory references (Article 35 GDPR criteria), optional override capability for DPO to require DPIA even if score below threshold with justification field, and automatic DPIAAssessment creation when required with screening responses pre-populated; configure questionnaire to be auto-triggered when new ProcessingActivity is approved and involves any high-risk indicators; publish template to enable systematic DPIA requirement determination with regulatory compliance. `M`

35. [ ] Component Snapshot for Document Generation — Implement SnapshotService creating immutable copies of all components referenced by DPIAAssessment at generation time, storing snapshot as nested JSON in DPIAAssessment.metadata including full details of DataProcessingActivity (name, description, purposes with full text, dataSubjects with categories, dataCategories with sensitivity, recipients with types and locations, legalBasis with full article text), all linked Processors with DPA status and locations, all DataTransfers with mechanisms and geography, all Risks with controls, all SecurityMeasures, timestamp of snapshot creation, and component version hashes for change detection; implement snapshot comparison detecting when current component data differs from snapshot with visual "outdated warning" indicator on DPIA showing "3 processors updated since last generation" with option to review changes and regenerate; create snapshot restore preview showing side-by-side old vs new component data before regeneration decision; design snapshot schema for future bidirectional sync where edits to generated documents update components while respecting snapshot versioning to prevent documents from changing unexpectedly when underlying components are edited while enabling controlled updates with full change visibility. `M`

36. [ ] DPIA Full Assessment Questionnaire — Create comprehensive DPIA questionnaire template with 40-50 questions organized in sections (Necessity & Proportionality, Data Minimization, Data Subject Rights, Security Measures, Risk Identification, Consultation, DPO Opinion) covering detailed necessity justification with alternatives considered, proportionality assessment with balancing test for legitimate interest, data minimization measures and retention justification, detailed description of security measures (encryption, access controls, logging) with references to SecurityMeasure components, systematic risk identification prompts for each RiskCategory with likelihood/impact assessment guidance, control effectiveness evaluation with residual risk calculation, data subject consultation evidence (method, findings, impact on design), and DPO opinion documentation (recommendations, approval/rejection, conditions); implement smart suggestions pulling from existing Controls and SecurityMeasures in organization library, auto-populate sections from linked ProcessingActivity components where possible (purposes, legal basis, data categories), configure conditional logic showing relevant questions based on screening results (e.g., only ask about automated decision explanations if involvesAutomatedDecisions=true), and set required fields per regulatory requirements (consultation mandatory if high risk); integrate with risk scoring algorithm updating DPIAAssessment.overallRiskLevel based on aggregated risks to enable comprehensive DPIA documentation with regulatory completeness. `L`

37. [ ] Document Generation Infrastructure with Versioning — Implement GeneratedDocument model with organizationId, documentType enum (ROPA, DPIA, LIA, DPA, PRIVACY_STATEMENT, DTIA), version string ("1.0", "1.1", "2.0"), assessmentId/dataProcessingActivityId nullable FKs linking to source, **dataSnapshot JSON freezing ALL referenced components at generation time** (complete Vendor records, Purpose details, DataCategory definitions, Risk assessments, SecurityMeasure specifications with timestamps and version hashes), wordFileUrl, pdfFileUrl, markdownContent for search, generatedAt timestamp, generatedBy userId, DocumentStatus enum (DRAFT, FINAL, SUPERSEDED, ARCHIVED), **supersededById self-reference creating version chains**, approvedAt, approvedBy, approvalNotes, and audit timestamps; implement version comparison service detecting changes between snapshots with field-level diffing; build version suggestion logic (increment minor for component updates, increment major for structural changes); create superseding workflow prompting user decision ("Mark v1.0 as SUPERSEDED or keep both FINAL?"); add indexes on (organizationId, documentType, status), (version), (generatedAt), and (supersededById); implement snapshot integrity validation preventing generation with missing component references; test version chain queries and superseding cascades to enable immutable document history with explicit version lifecycle management. `M`

**Milestone 8: DPIA Assessment Complete** ✓ Full DPIA workflow from screening to detailed assessment

### Document Generation Engine

38. [ ] DPIA Template Auto-Generated Sections — Create DPIA Docxtemplater template (.docx file) with professional formatting including cover page with processing activity name, organization details, version, date, and approval signatures; table of contents with automatic page numbering; management summary with variable injection ({{activity.name}}, {{activity.description}}, {{dpia.overallRiskLevel}}); fully auto-generated sections pulling from component snapshot including personal data categories table with columns (category, sensitivity, special category flag, collection method, retention period) iterating over snapshot.dataCategories, data processor table with columns (processor name, role, location, DPA status, DPA expiry date) iterating over snapshot.processors with conditional formatting (red text if DPA expired), processing locations table showing all DigitalAssets with hosting locations and transfer mechanisms where applicable, legal basis section with Article references and justification text from snapshot.legalBasis, retention periods table with columns (data category, retention duration, legal basis, deletion method), security measures section with bullet list from snapshot.securityMeasures, and data subject rights implementation section from snapshot.dataSubjectRightsImplementation components; implement template variable resolver service translating snapshot JSON paths to Docxtemplater syntax, conditional sections showing/hiding based on data presence (e.g., only show international transfers section if transfers exist), and table row iteration with proper Word table formatting to generate 60-70% of DPIA content automatically with professional quality matching legal expectations. `M`

39. [ ] DPIA Template Free-Text Override Sections — Implement template-with-override pattern for DPIA sections requiring professional judgment including risk assessment matrix with default risks from DPIARisk components but allowing manual override in TipTap rich text editor, necessity and proportionality analysis with suggested text from questionnaire responses but editable for nuanced legal arguments, data subject consultation findings with default from questionnaire but expandable for detailed analysis, DPO opinion section fully free-text for professional assessment with signature block, and residual risk evaluation with suggested text from risk calculations but overridable for final determination; build TipTap editor integration with variable support ({{activity.name}} available in free text), Word-like formatting toolbar (headings, bold, italic, lists, tables), comment capability for internal notes, and diff view showing changes between versions; implement override storage in DPIAAssessment.metadata separate from component data, version tracking when overrides change, and template regeneration preserving overrides while updating auto-generated sections to enable privacy officers to customize DPIAs while maintaining data integrity and automatic updates of factual content. `S`

40. [ ] Word Export with Docxtemplater — Implement DocumentGenerationService using Docxtemplater library, load DPIA template .docx file from filesystem, inject variables from DPIAAssessment snapshot and free-text overrides, handle table iteration for repeated sections (processors, data categories, risks) with proper Word table row cloning, apply conditional logic hiding empty sections, maintain professional formatting with styles (Heading 1-4, Body Text, Table styles), generate headers/footers with document metadata (title, version, page numbers, confidentiality notice), create automatic table of contents from heading styles, implement digital signature placeholder for approval workflows, generate unique filename (DPIA_ActivityName_v1.0_2024-01-15.docx), store generated file in S3-compatible storage (MinIO locally, S3/R2 in production) with presigned URL for secure download, track generation metadata (who generated, when, template version used) in database, and implement version comparison highlighting differences between document versions to enable legal teams to work in preferred Word format with professional quality output. `M`

41. [ ] PDF Export with Puppeteer — Implement PDF generation service using Puppeteer with headless Chrome, convert DPIA template to HTML using same Docxtemplater data injection, apply professional CSS styling matching Word output with print-optimized margins, page breaks, headers/footers, render HTML to PDF maintaining perfect visual fidelity with table pagination handling, embedded fonts for consistent rendering across platforms, generate PDF metadata (title, author, creation date, keywords for searchability), implement digital signature support with signature appearance and certificate embedding, add watermark option (Draft, Confidential, Final) with diagonal text overlay and opacity control, optimize PDF size with compression while maintaining readability, store in S3 with presigned URL, and track generation in database to provide read-only distributable format for external stakeholders, regulators, and audit evidence. `S`

**Milestone 9: Document Generation Complete** ✓ Professional DPIA documents in Word and PDF

### Dashboard & Notifications

42. [ ] Pre-Computed Dashboard Metrics — Implement ComplianceDashboardMetrics model with organizationId, calculated metrics (totalProcessingActivities, activeProcessingActivities, requiresDPIACount, dpiaCompletedCount, highRiskActivitiesCount, totalVendors, activeVendors, criticalRiskVendors, vendorsWithoutDPA, vendorsDueForReview, pendingAssessments, overdueAssessments, completedThisMonth, openDSARs, overdueDSARs, averageResponseTimeDays, totalCrossBorderTransfers, transfersWithoutMechanism, expiredTransferMechanisms), and calculatedAt timestamp; implement MetricsCalculationService running on nightly cron job (2am UTC) executing optimized aggregation queries across all organizations, calculating all metrics in single database transaction, storing results in metrics table, and logging calculation duration for performance monitoring; add indexes on (organizationId, calculatedAt) for fast lookups; build DPO dashboard querying latest metrics instead of expensive live aggregations, displaying key metrics in card grid (Activities requiring DPIA with completion percentage, Vendors without valid DPA with count and risk score, Overdue assessments with list and assignees, Cross-border transfers without mechanisms with count), trend charts showing metrics over time (last 30/90 days), and drill-down links to filtered list views; implement real-time counter for time-critical metrics (assessments due today) supplementing nightly batch to provide DPOs with instant compliance overview without performance impact. `M`

43. [ ] Notification Rule Engine — Implement NotificationRule model with organizationId, TriggerType enum (ASSESSMENT_DUE, ASSESSMENT_OVERDUE, VENDOR_REVIEW_DUE, DPA_EXPIRING, TRANSFER_MECHANISM_EXPIRING, DSAR_DUE, DSAR_OVERDUE, HIGH_RISK_ACTIVITY_CREATED, CONSENT_EXPIRING), triggerConditions JSON (e.g., {"daysBeforeDue": 3, "assessmentType": "DPIA"}), recipient targeting (recipientRole for role-based, recipientUserId for specific user, recipientEmail for external), notificationChannel array (EMAIL, IN_APP, SLACK if configured), template string with variable support, and isActive flag; implement NotificationLog model tracking sentTo, sentVia channel, subject, body, sentAt timestamp, deliveredAt, openedAt, clickedAt for analytics; build NotificationCheckService running every 4 hours checking all active rules, querying relevant entities based on trigger conditions (e.g., assessments with dueDate between now and now+3days for ASSESSMENT_DUE), generating notifications for matches not already sent (check log for duplicate prevention), enqueueing notification jobs in BullMQ, and logging all checks for debugging; implement notification delivery service supporting email via Resend with React Email templates and in-app notifications stored in database with read/unread status; build notification preferences UI allowing users to customize frequency and channels per trigger type to enable automated reminders and escalations with configurable rules. `M`

44. [ ] Asset Integration Foundation — Implement AssetIntegration model with digitalAssetId (unique one-to-one), connectorType string (salesforce, aws-s3, postgres, google-workspace, manual for non-integrated assets), connectionConfig JSON (encrypted credentials, API endpoints, connection test timestamp) marked sensitive, scanFrequency enum (CONTINUOUS, DAILY, WEEKLY, MONTHLY, MANUAL_ONLY), lastScanDate and nextScanDate timestamps, discoveredDataCategories array, discoveredPIICount and discoveredRecordCount integers, ScanStatus enum (ACTIVE, PAUSED, FAILED, NOT_CONFIGURED), lastScanError text for diagnostics, autoPopulateAssessments boolean enabling automatic questionnaire pre-filling, confidenceThreshold float (default 0.85) for ML classification, and audit timestamps; implement AssetScanLog model with assetIntegrationId reference, scanDate, recordsScanned count, piiDetected JSON (e.g., {"email": 1500, "phone": 300}), changesSinceLastScan JSON showing new/removed data categories, scanDuration, and scanStatus; add indexes on (scanStatus, nextScanDate) for scheduled job queries; build manual discovery UI allowing users to flag DigitalAsset with discoveredVia="salesforce" and add basic metadata even without active connector, preparing foundation for future automated discovery while enabling current manual tracking; create admin connector management page (future use) with connector list, test connection button, and scan history to plant seeds for DataGrail-style automated discovery pattern while delivering immediate value through manual discovery tracking. `S`

**Milestone 10: MVP Complete** ✓ Core value proposition delivered: component library + questionnaires + document generation + dashboard

### Beta Phase: Collaboration & Intelligence

45. [ ] Document Regeneration Workflow — Implement impact analysis service detecting when components referenced in document snapshots have changed since generation, displaying ChangeImpactDialog showing "Google Cloud processor updated: DPA expiry changed from 2025-12-31 to 2026-06-30" with affected documents list (DPIA v1.2, DPIA v1.3, RoPA v2.0); build regeneration decision workflow with options (Generate new version keeping old, Replace existing and supersede, Generate as draft for review); implement selective regeneration allowing users to pick which documents to update; create batch regeneration for bulk updates; add regeneration preview showing side-by-side comparison (old snapshot vs current components) with highlighted changes; implement regeneration queue with progress tracking for large document sets; build notification service alerting document owners when components change ("3 of your DPIAs may need regeneration"); test regeneration with concurrent component updates to enable controlled document updates responding to component changes without automatic invalidation. `L`

**Milestone 11.5: Intelligent Document Lifecycle** ✓ _Smart regeneration with change awareness_ 46. [ ] Bidirectional Document Sync — Implement document metadata embedding in Word .docx custom properties storing generation timestamp, template version, component snapshot hash, and organization ID; build change detection algorithm comparing original generated .docx with uploaded edited .docx using docxtemplater-extract parsing both documents, comparing table rows for processor/data category additions/removals/edits, comparing text fields for description/justification changes, generating structured diff JSON with changeType (added, removed, modified), componentType, oldValue, newValue, and confidence score; create UserReviewDialog component displaying changes in side-by-side view (left: original, right: edited) with approve/reject buttons per change, bulk approve/reject for entire section, and conflict warning if underlying component changed since generation; implement component update service applying approved changes to Purpose/Processor/DataCategory/Risk components with transaction handling, update change log, and mark approval in document history; build conflict resolution workflow when components changed between generation and upload showing three-way merge (original snapshot, current component, uploaded edit) with user selection; trigger affected document regeneration queue for all DPIAs using updated components with user notification of pending updates to enable legal teams to edit in Word while maintaining bidirectional data flow with full audit trail and conflict handling. `2XL`

47. [ ] Collaboration System — Build Comment model with commentableType (ProcessingActivity, Assessment, DPIAAssessment, Vendor, Risk), commentableId, userId, content with @mention parsing, isInternal flag for hiding from external stakeholders, parentCommentId for threading, and audit timestamps; implement @mention detection with user search, real-time notification to mentioned users, and email digest for unread mentions; create Approval model with assessmentId, approverId, ApprovalStatus, comments, requestedAt, respondedAt tracking approval workflow steps; build structured approval flow with WorkflowStage transitions (PRIVACY_REVIEW → IT_REVIEW → LEGAL_REVIEW → DPO_REVIEW) configurable per assessment type, automatic assignment to role on stage entry, and parallel approval support for multiple reviewers; implement comprehensive notification system via Resend + React Email templates covering assignment notifications (you've been assigned assessment X, due in 3 days), status change notifications (assessment moved to LEGAL_REVIEW, your input needed), approval request notifications (please review and approve DPIA Y), comment notifications (@mentioned in comment thread, new reply to your comment), reminder notifications (assessment due tomorrow, DPA expires in 30 days), and deadline notifications (assessment overdue by 2 days, escalated to manager); build ActivityFeed component showing chronological stream of all changes across organization (new activities created, assessments completed, components updated, approvals granted, risks escalated) with filtering by entity type, user, and date range; create in-app notification center with unread badge count, grouped notifications (3 new comments on your DPIA), mark all as read, and notification preferences to enable team collaboration with clear accountability and communication. `L`

48. [ ] Smart Suggestions System — Implement ComponentReuseIntelligence analyzing historical patterns across organization's ProcessingActivity completions, building component co-occurrence graph (Purpose X is used with DataCategory Y in 80% of activities), identifying commonly-used component combinations per business unit or project type, and scoring suggestions by frequency and recency; build SuggestionService providing context-aware recommendations when user starts new ProcessingActivity questionnaire, analyzing initial responses (project type, business unit, data subjects) and returning ranked list of suggested Purposes, DataCategories, Recipients, and SecurityMeasures with explanation of why suggested (e.g., "Used in 8 of 10 similar marketing projects"); implement pre-fill capability from similar past activities with similarity algorithm comparing data subjects, purposes, and business unit, showing user "This looks similar to Activity X, pre-fill from there?" with preview of components to be copied; build DuplicateDetection service running on activity creation, comparing new activity against existing using name similarity (Levenshtein distance), component overlap percentage, and business unit, flagging potential duplicates with warning modal "Activity 'Customer Newsletter 2024' looks similar to existing 'Newsletter Campaign 2023', continue anyway or link as related?"; implement CompletionSuggestions analyzing partially-completed assessments, identifying missing required fields or common overlooked items (e.g., "Activities with special category data usually include Certification components, add one?"), estimating time to complete based on remaining required questions weighted by historical response times, and providing checklist of recommended next steps; create OrganizationLearning service tracking patterns like "In this organization, marketing activities always include Legitimate Interest Assessment, pre-filling that questionnaire?" enabling system to learn organization-specific patterns and provide increasingly personalized suggestions over time; build suggestion acceptance tracking to improve ML model, and admin analytics dashboard showing suggestion acceptance rates and component reuse metrics to demonstrate time savings and consistency improvements. `M`

49. [ ] Additional Document Templates — Create DataProcessingAgreement Docxtemplater template with controller and processor details pulled from Vendor and Organization components, scope of processing section with purposes and data categories from ProcessingActivity, security measures from linked SecurityMeasure components, sub-processor authorization clauses with current sub-processor list from Recipient hierarchy, data subject rights support clauses, breach notification procedures from Organization.settings, audit rights, data return/deletion procedures, liability and indemnification, term and termination, and signature blocks; implement variable injection from multiple entity types (Activity, Vendor, Organization), generate DPA per vendor-activity relationship with unique naming, and store generated DPAs linked to Vendor.dpaDocumentUrl for lifecycle tracking; create PrivacyStatement template aggregating all active ProcessingActivity components into public-facing documentation, grouping by purpose (Marketing, Analytics, Essential), listing data categories collected per purpose, explaining legal basis in plain language, detailing data subject rights with contact information and request procedures, listing recipients and international transfers, stating retention periods, and including cookie policy if applicable; implement automatic regeneration workflow when underlying activities change with approval gate before publishing updated privacy statement; build ConsentForm template based on activity's legal basis requirements, generating granular consent checkboxes per purpose, including withdrawal instructions, embedding version tracking, and outputting web-embeddable HTML form or printable PDF; create admin template management UI for customizing organization-specific headers, footers, and legal language while maintaining regulatory completeness to enable comprehensive document generation beyond DPIAs for complete GDPR documentation suite. `M`

50. [ ] Risk Assessment Workflows — Build RiskReviewWorkflow where privacy officers review auto-detected risks from questionnaire responses (special category data = confidentiality risk, automated decisions = discrimination risk, large scale processing = data breach risk with suggested RiskCategory and initial likelihood/impact based on activity characteristics), present suggested risks in review UI with accept/modify/reject actions, add manual risks through risk identification wizard prompting for risk description, category selection, affected data subject groups, likelihood assessment guidance (how often could this occur?), impact assessment guidance (what harm could result?), inherent risk calculation (Likelihood × Impact matrix), and link to existing Controls or create new control implementations; implement residual risk calculation service applying control effectiveness ratings to inherent risks, displaying risk reduction from controls (e.g., Inherent: High → Residual: Medium after encryption + access controls), recalculating overall activity risk level, and updating DPIAAssessment.overallRiskLevel; build RiskMatrix visualization component with color-coded heat map (green: low, yellow: medium, red: high, dark red: critical), interactive cells showing risks in each likelihood/impact combination, drill-down to risk details and linked controls, and filter by activity, data category, or risk status; create RiskHeatmap dashboard aggregating risks across all activities, highlighting areas of concentration (e.g., many confidentiality risks in marketing activities suggesting pattern), trend analysis showing risk levels over time, and risk aging report showing risks open >30/60/90 days without mitigation; implement risk approval workflow where high/critical residual risks require executive signoff, DPO opinion for risk acceptance, and periodic risk review reminders based on activity review dates; build risk reporting with exports to PDF/Excel including full risk register with all details, executive risk summary for board reporting, and compliance evidence package for audits to enable comprehensive risk management workflow from identification through mitigation and monitoring. `L`

**Milestone 11: Beta Phase Complete** ✓ Collaboration and intelligence features increase multi-user value and reduce manual work

### Scale Phase: Integrations & Enterprise

51. [ ] Microsoft Word Plugin — Develop Office.js add-in with React components, implement ComponentPanel sidebar showing activity-linked Purposes/Processors/Recipients with filter and search, display linked Risks and Controls with status indicators, and show SecurityMeasures with implementation status; build inline warnings using Word content controls, detect missing required fields in document body (e.g., no DPA expiry date for processor mention), highlight text spans with yellow background and tooltip explaining issue, and provide quick action buttons in task pane to add missing component or update existing; implement QuickActions buttons for common tasks (add new Processor while reviewing DPA section, link Risk while documenting threat, add Control while describing security), opening inline forms in task pane, saving to Compilo backend via REST API, and updating Word document content with newly added component details; build LiveSync functionality with WebSocket connection to Compilo backend, subscribing to component updates for current document's linked activity, receiving real-time push notifications when teammate edits linked processor or risk, showing toast notification with change summary and option to refresh document sections, and implementing conflict detection if user also editing same section; implement offline mode with local storage queuing changes when disconnected, syncing queued changes on reconnection with conflict resolution, and showing offline indicator in add-in with pending changes count; integrate full authentication flow with OAuth, organization selection, and document linking wizard on first open; build admin deployment guide with Office 365 admin center upload, manifest configuration, and user installation instructions to enable seamless Word integration for legal teams with real-time data access and collaborative editing. `XL`

52. [ ] REST API & GraphQL Layer — Build comprehensive REST API with Express.js server on dedicated /api route, implement JWT authentication with API key support for machine-to-machine, rate limiting with Redis (100 requests/minute per key), and API versioning (/api/v1/); create CRUD endpoints for all core entities: POST/GET/PUT/DELETE for ProcessingActivity, Vendor, DataAsset, Purpose, LegalBasis, DataCategory, Risk, Control with nested relationship creation (create activity with linked purposes in single request), bulk operations endpoints (POST /api/v1/activities/bulk with array of activities), filtering query parameters (?status=ACTIVE&riskLevel=HIGH), pagination with cursor-based navigation (better than offset for large datasets), and sorting (sort=createdAt:desc); implement GraphQL schema using Pothos or TypeGraphQL providing nested relationship queries (query activity { purposes { name } dataSubjects { category } risks { controls { name } } } fetching full graph in single request), query optimization with DataLoader preventing N+1 queries, field-level authorization ensuring users only access their organization's data, and subscription support via WebSockets for real-time updates; create OpenAPI/Swagger documentation with automatic generation from Zod schemas, interactive API explorer with try-it-out functionality, code examples in multiple languages (JavaScript, Python, curl), authentication guide with example API key flow, rate limit documentation, and webhook payload examples; build API analytics dashboard showing usage by endpoint, error rates, response times, most active API consumers, and rate limit violations; implement API versioning strategy with deprecation warnings, migration guides, and backward compatibility guarantees to enable external integrations and custom automation workflows with production-grade API infrastructure. `L`

53. [ ] Webhook System — Implement Webhook model with organizationId, event type subscription array (e.g., [dpa.expiring, dpia.approved, component.updated, risk.threshold_breached]), target URL, secret for HMAC signature verification, isActive flag, retry configuration (maxRetries: 3, backoffMultiplier: 2), and metadata for custom filtering; build WebhookDeliveryService with event bus pattern using BullMQ subscribing to application events (Activity created, Assessment completed, DPA expiring alert, Risk escalated), matching subscribed webhooks for organization, constructing webhook payload with event type, timestamp, organization ID, resource ID, and nested resource data, generating HMAC-SHA256 signature using webhook secret, enqueueing delivery job in dedicated webhook queue, and implementing exponential backoff retry (immediate, 1min, 5min, 30min) with permanent failure logging after max retries; create WebhookDeliveryLog model tracking webhookId, eventType, payload, deliveryStatus (pending, succeeded, failed), httpStatus, responseBody, attempts count, and timestamps for debugging; implement webhook verification endpoint allowing clients to verify configuration, send test payload, and validate signature handling; build webhook management UI with webhook list showing success/failure rates, add/edit webhook form with event type checkboxes and URL validation, test webhook button sending sample payload and displaying response, delivery log view with retry button for failed deliveries, and webhook health dashboard showing delivery success percentage and average response times; create webhook examples documentation for common integrations (Slack notifications on DPA expiry, Jira ticket creation for high risks, PagerDuty alert for critical findings) including payload schemas, signature verification code samples, and troubleshooting guide to enable real-time integration with external systems and custom alerting workflows. `M`

54. [ ] Integration Connectors — Build HR system connector (BambooHR, Workday, Personio) syncing employee data to automatically create/update employee-related ProcessingActivities (recruitment, payroll, performance management), mapping HR data fields to DataCategory components, detecting new employees triggering onboarding privacy workflow, and syncing terminations to archive related activities; create CRM connector (Salesforce, HubSpot, Pipedrive) importing customer/contact objects as DataSubject volume estimates, syncing opportunity/deal stages to processing activity lifecycle, mapping custom fields to data categories, and auto-creating marketing consent records from CRM consent flags; build ISMS connector (Vanta, Drata, Secureframe) exporting Compilo risks to ISO 27001 risk register with bidirectional sync, mapping Compilo SecurityMeasure to ISO controls, syncing audit findings back to Compilo as risks, and generating compliance evidence exports for certification audits; implement GRC platform connector (OneTrust, TrustArc, ServiceNow GRC) with bidirectional sync of processing activities to avoid duplication, syncing DPIA assessments and results, importing vendor assessments from GRC tool, and exporting Compilo RoPA to external compliance platform; create procurement system connector (Coupa, SAP Ariba) importing new vendor contracts triggering vendor onboarding workflow, syncing contract expiry dates to DPA expiry tracking, flagging data processing vendors for privacy review, and auto-creating vendor risk assessments; implement universal webhook-based connector framework allowing custom integrations with Zapier/Make.com actions, CSV import/export for batch operations, and API examples for custom connectors; build connector management admin UI with available connectors catalog, configuration wizard per connector (API credentials, field mappings, sync frequency), sync status dashboard showing last successful sync and error log, manual sync trigger for testing, and connector health monitoring; create integration documentation with setup guides per system, field mapping best practices, common error resolutions, and example workflows to enable seamless data exchange with external systems reducing manual data entry and ensuring consistency across compliance ecosystem. `XL`

55. [ ] Analytics Dashboard — Build executive compliance health overview displaying overall compliance score calculated from weighted metrics (activities with complete documentation, DPIAs completed on time, vendors with valid DPAs, risks with controls, assessments approved), status breakdown pie charts (activities by status, assessments by status, risks by level), risk distribution histogram (count of risks per likelihood/impact cell), upcoming obligations timeline (DPIAs due, DPA renewals, assessment deadlines, risk review dates), and compliance trend line (score over last 12 months with annotated changes); create processor inventory dashboard with world map visualization showing processor locations with dot size by data volume, region distribution bar chart (EU: 45%, US: 30%, APAC: 15%, Other: 10%), DPA status pie chart (valid, expiring <30 days, expired), most-used processors ranked list with activity count and risk tier, processor risk heatmap showing processor vs. risk category matrix, subprocessor depth analysis (how many levels deep in chain), and new processor trend (processors added per month); implement data category heatmap showing which categories are processed where with matrix visualization (rows: data categories, columns: processing locations/processors, cells: color intensity by volume), special category data concentration identifying activities/processors with most Article 9 data, data flow sankey diagram visualizing data movement from collection through processing to recipients with line thickness by volume, retention analysis showing data categories by retention period distribution, and orphaned data detection highlighting categories without clear retention rules; build risk matrices with likelihood vs. impact grid, risk by category breakdown, risk trend showing opened vs. closed risks over time, mean-time-to-mitigate calculation, risk ownership distribution, control effectiveness ratings showing average effectiveness per control type, and residual risk acceptance analysis (percentage of risks accepted vs. `M`itigated); create trend analysis with time-series charts for all key metrics over 30/90/365 days, comparative analysis between business units or project types, milestone tracking showing compliance improvement initiatives and their impact, and predictive analytics forecasting future risk levels or DPA expirations requiring action; implement dashboard customization allowing users to pin favorite widgets, customize date ranges, set comparison baselines, and create custom dashboard views per role (DPO vs. executive vs. auditor); build dashboard export to PDF executive report with snapshot date, key findings summary, and all visualizations, and scheduled dashboard delivery via email weekly/monthly to enable data-driven compliance oversight and board-level reporting. `L`

56. [ ] Background Job System — Set up BullMQ with Redis as job queue infrastructure, create dedicated queues for different job types (document-generation, email, webhook-delivery, scheduled-tasks, asset-scanning), implement worker processes in separate Node processes for scaling, and configure job prioritization; build document generation job handlers processing DPIA generation requests asynchronously (offload from HTTP request), tracking progress with percentage updates for long documents, implementing job timeout (5 minutes) with cleanup, storing generated documents in S3, and sending completion notification to user; create email job handlers with rate limiting (100 emails/hour per organization to prevent spam), batch sending with personalized content per recipient, bounce handling with automatic retry on transient failures, and unsubscribe link inclusion for automated emails; implement scheduled job system with cron patterns for recurring tasks: nightly metrics calculation (2am UTC calculating ComplianceDashboardMetrics), DPA expiry checks (daily at 6am checking vendors with dpaExpiryDate within next 30 days and triggering notifications), DPIA review reminders (weekly on Monday checking activities with nextReviewDate approaching and sending assignment notifications), stale risk detection (monthly identifying risks without updates in 90+ days and alerting owners), and data deletion checks (weekly identifying RetentionSchedule items past expiration triggering deletion workflow); build job monitoring dashboard with queue health showing pending/active/completed/failed counts per queue, job execution time percentiles (p50, p95, p99) per job type, failure rate tracking with retry attempts, worker health monitoring showing active workers and their current jobs, and job history with search/filter capability; implement dead letter queue for permanently failed jobs with manual retry capability and alerting on DLQ accumulation; create admin job management UI with pause/resume queue buttons, manual job retry, clear failed jobs action, and job inspection showing full payload and error details; optimize job performance with batching (combine 100 individual email jobs into single batch job), deduplication (don't enqueue identical jobs within time window), and idempotency (jobs can safely retry without side effects) to enable reliable asynchronous processing with operational visibility and scalability for high-volume organizations. `M`

57. [ ] Advanced Search & Reporting — Implement PostgreSQL full-text search using pg_trgm extension, create tsvector columns on searchable text fields (ProcessingActivity.name, description, Vendor.name, Purpose.name), set up GIN indexes on tsvector columns for fast search, and build search query parser supporting multi-word phrases, fuzzy matching with typo tolerance, and result ranking by relevance; create unified search API searching across all entity types (Activities, Vendors, Assessments, Risks, Components) with single query, returning grouped results by entity type with count per type, highlighting matched terms in result snippets, and providing faceted filtering on search results (filter activities by status, vendors by risk tier); implement advanced filtering UI with multi-criteria builder supporting field operators (contains, equals, greater than, less than, in, not in), logical operators (AND, OR, NOT) for combining criteria, nested condition groups with parentheses, date range pickers for temporal filtering, and multi-select for enum fields; build saved filter feature allowing users to name and save complex filter combinations, make filters public/private (share with team or keep personal), set default filters per page, and organize filters in folders; create custom report builder with drag-drop interface for column selection (choose which fields to include from Activity, related Purposes, linked Risks, etc.), report template system with predefined useful reports (All High-Risk Activities, Vendors Due for Review, Overdue Assessments, Cross-Border Transfers by Country), calculated fields (days until DPA expiry, activity age, risk score), grouping and aggregation (group by business unit, sum risk counts, average assessment completion time), sorting and filtering on report output, and preview before export; implement report export to multiple formats: Excel with formatted cells, formulas, and pivot tables; CSV for raw data analysis in external tools; PDF with professional formatting and branding; and JSON for programmatic consumption; build scheduled report generation with cron configuration (daily, weekly, monthly on specific day/time), email delivery to distribution lists with attachment or link to download, and report history showing past generated reports with download links; create report sharing with link generation, access control per report (who can view/edit/run), and collaborative report editing allowing teams to refine reports together; build report analytics showing most-used reports, average execution time, and user adoption to identify valuable reports; optimize query performance with materialized views for common aggregations, query result caching with Redis for frequently-run reports, and incremental refresh for large datasets to enable power users to extract insights from compliance data and demonstrate value to stakeholders through evidence-based reporting. `L`

**Milestone 12: Enterprise Ready** ✓ Integrations, analytics, and scalability features enable enterprise adoption

---

## Additional Resources

**[Roadmap Strategic Notes](./roadmap-notes.md)** - Detailed product planning context, success metrics, risk assessment, and go-to-market strategy for this roadmap
